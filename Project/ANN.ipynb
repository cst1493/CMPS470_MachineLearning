{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports:\n",
    "#install tensorflow, keras, pandas, & scikitlearn.\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler ###\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#from sklearn import metrics\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Date        Open        High         Low       Close    Profit\n",
       "0   1/1/2001  268.399994  268.399994  267.299988  268.000000 -1.529853\n",
       "1   1/8/2001  268.000000  268.000000  263.899994  263.899994  0.151570\n",
       "2  1/15/2001  263.299988  264.299988  263.200012  264.299988 -0.567537\n",
       "3  1/22/2001  266.399994  266.399994  262.799988  262.799988  1.636232"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Profit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1/1/2001</td>\n      <td>268.399994</td>\n      <td>268.399994</td>\n      <td>267.299988</td>\n      <td>268.000000</td>\n      <td>-1.529853</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1/8/2001</td>\n      <td>268.000000</td>\n      <td>268.000000</td>\n      <td>263.899994</td>\n      <td>263.899994</td>\n      <td>0.151570</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1/15/2001</td>\n      <td>263.299988</td>\n      <td>264.299988</td>\n      <td>263.200012</td>\n      <td>264.299988</td>\n      <td>-0.567537</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1/22/2001</td>\n      <td>266.399994</td>\n      <td>266.399994</td>\n      <td>262.799988</td>\n      <td>262.799988</td>\n      <td>1.636232</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "data_ANN = pd.read_csv('GoldWeekly2001-2021.csv')\n",
    "\n",
    "data_ANN = data_ANN.drop('Did_Win', axis=1)\n",
    "data_ANN = data_ANN.drop('Volume', axis=1)\n",
    "\n",
    "for i in range(len(data_ANN)):\n",
    "    if data_ANN.iloc[i,-1] == 0:\n",
    "        continue\n",
    "    else:\n",
    "        data_ANN.iloc[i,-1] = data_ANN.iloc[i,-1] / data_ANN.iloc[i,-2] * 100\n",
    "\n",
    "data_ANN.head(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "Label = preprocessing.LabelEncoder()\n",
    "\n",
    "infoFromLabel = Label.fit_transform(data_ANN['Open'])\n",
    "#infoFromLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing data:\n",
    "data_labels = data_ANN['Date'].copy()\n",
    "data_ANN = data_ANN.drop('Date', axis = 1)\n",
    "\n",
    "#Split data for training and testing\n",
    "X_train, X_Test_Val = train_test_split(data_ANN, test_size = 0.4, train_size = 0.6, shuffle = False)\n",
    "X_test, X_val = train_test_split(X_Test_Val, test_size = 0.5, train_size = 0.5, shuffle = False)\n",
    "#Removing the labels from the data.\n",
    "train_labels = X_train['Profit'].copy()\n",
    "X_train = X_train.drop('Profit', axis = 1)\n",
    "\n",
    "test_labels = X_test['Profit'].copy()\n",
    "X_test = X_test.drop('Profit', axis = 1)\n",
    "\n",
    "val_labels = X_val['Profit'].copy()\n",
    "X_val = X_val.drop('Profit', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "20/20 - 20s - loss: 1.9916 - mae: 1.9916\n",
      "Epoch 2/25\n",
      "20/20 - 0s - loss: 1.9631 - mae: 1.9631\n",
      "Epoch 3/25\n",
      "20/20 - 0s - loss: 1.9605 - mae: 1.9605\n",
      "Epoch 4/25\n",
      "20/20 - 0s - loss: 1.9599 - mae: 1.9599\n",
      "Epoch 5/25\n",
      "20/20 - 0s - loss: 1.9638 - mae: 1.9638\n",
      "Epoch 6/25\n",
      "20/20 - 0s - loss: 1.9597 - mae: 1.9597\n",
      "Epoch 7/25\n",
      "20/20 - 0s - loss: 1.9597 - mae: 1.9597\n",
      "Epoch 8/25\n",
      "20/20 - 0s - loss: 1.9604 - mae: 1.9604\n",
      "Epoch 9/25\n",
      "20/20 - 0s - loss: 1.9577 - mae: 1.9577\n",
      "Epoch 10/25\n",
      "20/20 - 0s - loss: 1.9666 - mae: 1.9666\n",
      "Epoch 11/25\n",
      "20/20 - 0s - loss: 1.9616 - mae: 1.9616\n",
      "Epoch 12/25\n",
      "20/20 - 0s - loss: 1.9607 - mae: 1.9607\n",
      "Epoch 13/25\n",
      "20/20 - 0s - loss: 1.9613 - mae: 1.9613\n",
      "Epoch 14/25\n",
      "20/20 - 0s - loss: 1.9552 - mae: 1.9552\n",
      "Epoch 15/25\n",
      "20/20 - 0s - loss: 1.9610 - mae: 1.9610\n",
      "Epoch 16/25\n",
      "20/20 - 0s - loss: 1.9585 - mae: 1.9585\n",
      "Epoch 17/25\n",
      "20/20 - 0s - loss: 1.9584 - mae: 1.9584\n",
      "Epoch 18/25\n",
      "20/20 - 0s - loss: 1.9591 - mae: 1.9591\n",
      "Epoch 19/25\n",
      "20/20 - 0s - loss: 1.9579 - mae: 1.9579\n",
      "Epoch 20/25\n",
      "20/20 - 0s - loss: 1.9606 - mae: 1.9606\n",
      "Epoch 21/25\n",
      "20/20 - 0s - loss: 1.9591 - mae: 1.9591\n",
      "Epoch 22/25\n",
      "20/20 - 0s - loss: 1.9590 - mae: 1.9590\n",
      "Epoch 23/25\n",
      "20/20 - 0s - loss: 1.9592 - mae: 1.9592\n",
      "Epoch 24/25\n",
      "20/20 - 0s - loss: 1.9584 - mae: 1.9584\n",
      "Epoch 25/25\n",
      "20/20 - 0s - loss: 1.9600 - mae: 1.9600\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe9efc3dca0>"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "#Multi-layer-perceptron\n",
    "#print(X_train)\n",
    "\n",
    "arr_train_labels = np.array(train_labels)\n",
    "arr_test_labels = np.array(test_labels)\n",
    "arr_val_labels = np.array(val_labels)\n",
    "\n",
    "X_trainA = []\n",
    "X_trainB = []\n",
    "X_trainC = []\n",
    "X_trainD = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_trainA.append(X_train.iloc[i,0])\n",
    "    X_trainB.append(X_train.iloc[i,1])\n",
    "    X_trainC.append(X_train.iloc[i,2])\n",
    "    X_trainD.append(X_train.iloc[i,3])\n",
    "\n",
    "X_trainA = np.array(X_trainA)\n",
    "X_trainB = np.array(X_trainB)\n",
    "X_trainC = np.array(X_trainC)\n",
    "X_trainD = np.array(X_trainD)\n",
    "\n",
    "X_train_values = [X_trainA, X_trainB, X_trainC, X_trainD]\n",
    "\n",
    "#Convert Test data to numpy array\n",
    "X_testA = []\n",
    "X_testB = []\n",
    "X_testC = []\n",
    "X_testD = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    X_testA.append(X_test.iloc[i,0])\n",
    "    X_testB.append(X_test.iloc[i,1])\n",
    "    X_testC.append(X_test.iloc[i,2])\n",
    "    X_testD.append(X_test.iloc[i,3])\n",
    "\n",
    "X_testA = np.array(X_testA)\n",
    "X_testB = np.array(X_testB)\n",
    "X_testC = np.array(X_testC)\n",
    "X_testD = np.array(X_testD)\n",
    "\n",
    "X_test_values = [X_testA, X_testB, X_testC, X_testD]\n",
    "\n",
    "#Convert Validation data to numpy array\n",
    "X_valA = []\n",
    "X_valB = []\n",
    "X_valC = []\n",
    "X_valD = []\n",
    "\n",
    "for i in range(len(X_val)):\n",
    "    X_valA.append(X_val.iloc[i,0])\n",
    "    X_valB.append(X_val.iloc[i,1])\n",
    "    X_valC.append(X_val.iloc[i,2])\n",
    "    X_valD.append(X_val.iloc[i,3])\n",
    "\n",
    "X_valA = np.array(X_valA)\n",
    "X_valB = np.array(X_valB)\n",
    "X_valC = np.array(X_valC)\n",
    "X_valD = np.array(X_valD)\n",
    "\n",
    "X_val_values = [X_valA, X_valB, X_valC, X_valD]\n",
    "\n",
    "openPrice = keras.Input(shape=(1, 1), name='Open')\n",
    "highPrice = keras.Input(shape=(1, 1), name='High')\n",
    "lowPrice = keras.Input(shape=(1, 1), name='Low')\n",
    "closePrice = keras.Input(shape=(1, 1), name='Close')\n",
    "\n",
    "openLayer = LSTM(45, return_sequences=False)(openPrice)\n",
    "highLayer = LSTM(45, return_sequences=False)(highPrice)\n",
    "lowLayer = LSTM(45, return_sequences=False)(lowPrice)\n",
    "closeLayer = LSTM(45, return_sequences=False)(closePrice)\n",
    "\n",
    "output = keras.layers.concatenate([openLayer, highLayer, lowLayer, closeLayer])\n",
    "\n",
    "output = Dense(10, activation='linear', name='weightedOutput')(output)\n",
    "\n",
    "model = keras.Model(inputs = [openPrice, highPrice, lowPrice, closePrice], outputs = [output])\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mae\", metrics=\"mae\")\n",
    "\n",
    "model.fit(X_train_values, arr_train_labels, epochs=25, verbose=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RNN = Sequential()\n",
    "\n",
    "# #RNN.add.LSTM(LSTM(units=45, activation='relu', return_sequences=False, input_shape = (1, 4)))\n",
    "# RNN.add.LSTM(units=45, input_shape = (1, 1)) #, activation='relu', return_sequences=False))\n",
    "\n",
    "# print('2')\n",
    "# #Dropout regularization is a technique used to avoid overfitting when training neural networks\n",
    "# RNN.add(Dropout(0.2))\n",
    "# RNN.add(LSTM(units = 45, return_sequences = True))\n",
    "# RNN.add(Dropout(0.2))\n",
    "# RNN.add(LSTM(units = 45, return_sequences = True))\n",
    "# RNN.add(Dropout(0.2))\n",
    "# RNN.add(LSTM(units = 45))\n",
    "# RNN.add(Dropout(0.2))\n",
    "\n",
    "# RNN.add(Dense(units = 1))\n",
    "# RNN.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = 'accuracy')\n",
    "\n",
    "# #tf.keras.backend.set_floatx('float64')\n",
    "# #RNN.fit(X_train, train_labels, epochs = 100, batch_size = 32)\n",
    "# RNN.fit(X_values, arr_train_labels, epochs = 100)\n",
    "\n",
    "# display(RNN)\n",
    "\n",
    "\n",
    "# MLP = MLPRegressor(hidden_layer_sizes=(5,5,5), max_iter=20_000)\n",
    "# MLP.fit(X_train, train_labels)\n",
    "\n",
    "# results = MLP.predict(X_test)\n",
    "\n",
    "# result_df = pd.DataFrame(X_test)\n",
    "# result_df = result_df.assign(Profit = test_labels, Predictions = results)\n",
    "\n",
    "# display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#currentMoney = 1000\n",
    "\n",
    "#for ((length of testing data)-1)\n",
    "#    if predicting_a_win:\n",
    "#        currentMoney = currentMoney * (Profit[i] + 1)\n",
    "#    \n",
    "#print(CurrentMoney) #then do this for validation.\n",
    "#\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}